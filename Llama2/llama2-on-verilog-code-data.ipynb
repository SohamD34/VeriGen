{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8622643,"sourceType":"datasetVersion","datasetId":5161838}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install cupy-cuda11x","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:07:10.602506Z","iopub.execute_input":"2024-06-09T09:07:10.603316Z","iopub.status.idle":"2024-06-09T09:07:23.526940Z","shell.execute_reply.started":"2024-06-09T09:07:10.603251Z","shell.execute_reply":"2024-06-09T09:07:23.525339Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: cupy-cuda11x in /opt/conda/lib/python3.10/site-packages (13.1.0)\nRequirement already satisfied: numpy<1.29,>=1.22 in /opt/conda/lib/python3.10/site-packages (from cupy-cuda11x) (1.26.4)\nRequirement already satisfied: fastrlock>=0.5 in /opt/conda/lib/python3.10/site-packages (from cupy-cuda11x) (0.8.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q -U torch numpy shapely transformers peft datasets scipy einops evaluate trl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-09T09:07:23.530356Z","iopub.execute_input":"2024-06-09T09:07:23.531055Z","iopub.status.idle":"2024-06-09T09:07:35.352564Z","shell.execute_reply.started":"2024-06-09T09:07:23.531004Z","shell.execute_reply":"2024-06-09T09:07:35.351138Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install accelerate@git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:07:35.354959Z","iopub.execute_input":"2024-06-09T09:07:35.355356Z","iopub.status.idle":"2024-06-09T09:07:48.405103Z","shell.execute_reply.started":"2024-06-09T09:07:35.355313Z","shell.execute_reply":"2024-06-09T09:07:48.403844Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344\n  Using cached accelerate-0.28.0.dev0-py3-none-any.whl\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (2.3.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (0.23.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (2024.3.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (12.5.40)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate@ git+https://github.com/huggingface/accelerate.git@97d2168e5953fe7373a06c69c02c5a00a84d5344) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:07:48.406804Z","iopub.execute_input":"2024-06-09T09:07:48.407149Z","iopub.status.idle":"2024-06-09T09:08:01.309305Z","shell.execute_reply.started":"2024-06-09T09:07:48.407115Z","shell.execute_reply":"2024-06-09T09:08:01.308151Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.3.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.3.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.40)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    GenerationConfig,\n    set_seed\n)\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\nfrom tqdm import tqdm\nfrom trl import SFTTrainer\nimport torch\nimport time\nimport pandas as pd\nimport numpy as np\nfrom functools import partial\nfrom pynvml import *\nimport os\nfrom huggingface_hub import interpreter_login     \nimport warnings\nimport accelerate\nimport bitsandbytes as bnb\n\nwarnings.filterwarnings('ignore')\n\ninterpreter_login()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:01.312326Z","iopub.execute_input":"2024-06-09T09:08:01.312684Z","iopub.status.idle":"2024-06-09T09:08:31.338274Z","shell.execute_reply.started":"2024-06-09T09:08:01.312650Z","shell.execute_reply":"2024-06-09T09:08:31.337212Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"\n    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\n    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n    Setting a new token will erase the existing one.\n    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your token (input will not be visible):  ·····································\nAdd token as git credential? (Y/n)  Y\n"},{"name":"stdout","text":"Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Accelerate version: {accelerate.__version__}\")\nprint(f\"BitsAndBytes version: {bnb.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:31.339561Z","iopub.execute_input":"2024-06-09T09:08:31.339892Z","iopub.status.idle":"2024-06-09T09:08:31.345133Z","shell.execute_reply.started":"2024-06-09T09:08:31.339866Z","shell.execute_reply":"2024-06-09T09:08:31.344154Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Accelerate version: 0.28.0.dev0\nBitsAndBytes version: 0.43.1\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ['WANDB_DISABLED']=\"true\"                 # disable Weights and Biases\n\ndef print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n    \n    \ndef print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n\n\ndef gen(model,p,tokenizer,maxlen=100,sample=True):\n    toks = tokenizer(p, return_tensors=\"pt\")\n    res = model.generate(**toks.to(\"cuda\"), max_new_tokens=maxlen, do_sample=sample,num_return_sequences=1,temperature=0.1,num_beams=1,top_p=0.95,).to('cpu')\n    return tokenizer.batch_decode(res,skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:31.346301Z","iopub.execute_input":"2024-06-09T09:08:31.346684Z","iopub.status.idle":"2024-06-09T09:08:31.356621Z","shell.execute_reply.started":"2024-06-09T09:08:31.346656Z","shell.execute_reply":"2024-06-09T09:08:31.355678Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"## Preparing and Analysing Dataset","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/llm-design-data/df_small.csv')\ndataset = dataset[['Error','Correct']]\ndataset.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:31.357841Z","iopub.execute_input":"2024-06-09T09:08:31.358123Z","iopub.status.idle":"2024-06-09T09:08:32.014791Z","shell.execute_reply.started":"2024-06-09T09:08:31.358098Z","shell.execute_reply":"2024-06-09T09:08:32.013698Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"                                               Error  \\\n0  /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n1  // Two modules are built as part of solution\\n...   \n\n                                             Correct  \n0  /*\\n * Copyright 2012, Homer Hsing <homer.hsin...  \n1  // Two modules are built as part of solution\\n...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Error</th>\n      <th>Correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>// Two modules are built as part of solution\\n...</td>\n      <td>// Two modules are built as part of solution\\n...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Total length of the dataset -\",len(dataset))\n\nfor i in range(len(dataset)):\n    error, correct = dataset.iloc[i,0], dataset.iloc[i,1]\n    print(type(error), type(correct))\n    break","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:32.016156Z","iopub.execute_input":"2024-06-09T09:08:32.016479Z","iopub.status.idle":"2024-06-09T09:08:32.022363Z","shell.execute_reply.started":"2024-06-09T09:08:32.016453Z","shell.execute_reply":"2024-06-09T09:08:32.021225Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Total length of the dataset - 500\n<class 'str'> <class 'str'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Initialisation","metadata":{}},{"cell_type":"code","source":"%%time\nseed = 42\nset_seed(seed)\n\ncompute_dtype = torch.float16\nbnb_config = BitsAndBytesConfig(                               # Wrapper library around CUDA custom functions - optimises 8-bit, matrix multixns\n        load_in_4bit=True,                                     # using 4-bit/8-bit quantisation (here we have used 4 bit)\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=False,\n    )\n\nif torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:32.023723Z","iopub.execute_input":"2024-06-09T09:08:32.024006Z","iopub.status.idle":"2024-06-09T09:08:32.038424Z","shell.execute_reply.started":"2024-06-09T09:08:32.023982Z","shell.execute_reply":"2024-06-09T09:08:32.037479Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"CPU times: user 3.02 ms, sys: 0 ns, total: 3.02 ms\nWall time: 2.81 ms\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"''' LOADING THE DESIRED MODEL '''\n\nmodel_name = \"silverliningeda/llama-2-7b-silverliningeda-verilog-codegen\"\nmodel = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:32.039550Z","iopub.execute_input":"2024-06-09T09:08:32.039847Z","iopub.status.idle":"2024-06-09T09:08:38.808460Z","shell.execute_reply.started":"2024-06-09T09:08:32.039823Z","shell.execute_reply":"2024-06-09T09:08:38.807609Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8ccc085129944e5a1e7bd226447a0a0"}},"metadata":{}}]},{"cell_type":"code","source":"''' LOAD THE CORRESPONDING TOKENIZER '''\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nprint(print_number_of_trainable_model_parameters(model),\"\\n\")\nprint_gpu_utilization()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:38.809519Z","iopub.execute_input":"2024-06-09T09:08:38.809790Z","iopub.status.idle":"2024-06-09T09:08:39.026959Z","shell.execute_reply.started":"2024-06-09T09:08:38.809765Z","shell.execute_reply":"2024-06-09T09:08:39.026007Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"trainable model parameters: 262410240\nall model parameters: 3500412928\npercentage of trainable model parameters: 7.50% \n\nGPU memory occupied: 8722 MB.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Baseline model","metadata":{}},{"cell_type":"code","source":"dash_line = '-'.join('' for x in range(100))\nincorrect_code = \"\"\"\n    module half_adder(a,b,s,cout);\n\n    input a,b;\n    output s,cout;\n\n    assign s  a * b;\n    assign cout = a & b;\n\n    endmodule\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:39.028083Z","iopub.execute_input":"2024-06-09T09:08:39.028409Z","iopub.status.idle":"2024-06-09T09:08:39.032929Z","shell.execute_reply.started":"2024-06-09T09:08:39.028383Z","shell.execute_reply":"2024-06-09T09:08:39.032000Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"print(\"USER CASE 1\")\nprompt = f\"module half adder\"        \ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\nsample = model.generate(input_ids, pad_token_id=tokenizer.pad_token_id, max_length=256, temperature=0.5, top_p=0.9)\nprint(tokenizer.decode(sample[0]))\nprint(dash_line)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:39.036262Z","iopub.execute_input":"2024-06-09T09:08:39.036554Z","iopub.status.idle":"2024-06-09T09:08:55.849404Z","shell.execute_reply.started":"2024-06-09T09:08:39.036530Z","shell.execute_reply":"2024-06-09T09:08:55.848467Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"USER CASE 1\n<s> module half adder of width 32 [\n everybody ]\n  module half_adder (\n    input logic [31:0] A,\n    input logic [31:0] B,\n    input logic cin,\n    output logic [31:0] sum,\n    output logic cout\n  );\n\n  logic [31:0] sum_temp;\n  logic carry_temp;\n\n  assign {carry_temp, sum_temp} = A + B + cin;\n  assign sum = sum_temp;\n  assign cout = carry_temp;\nendmodule\n\nmodule half_adder_module (\n  input logic [31:0] A,\n  input logic [31:0] B,\n  input logic cin,\n  output logic [31:0] sum,\n  output logic cout\n);\n\nhalf_adder half_adder_inst (\n  .A (A),\n  .B (B),\n  .cin (cin),\n  .sum (sum),\n  .cout (cout)\n);\nendmodule\n\nendmodule\n\\end{code\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"USER CASE 2\")\nprompt = f\"module full adder\"        \ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\nsample = model.generate(input_ids, pad_token_id=tokenizer.pad_token_id, max_length=256, temperature=0.5, top_p=0.9)\nprint(tokenizer.decode(sample[0]))\nprint(dash_line)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:08:55.850819Z","iopub.execute_input":"2024-06-09T09:08:55.851231Z","iopub.status.idle":"2024-06-09T09:09:12.697888Z","shell.execute_reply.started":"2024-06-09T09:08:55.851192Z","shell.execute_reply":"2024-06-09T09:09:12.696918Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"USER CASE 2\n<s> module full adder of width 32 [\n everybody ]\n  module adder (\n    input logic [31:0] A,\n    input logic [31:0] B,\n    input logic cin,\n    output logic [31:0] sum,\n    output logic cout\n  );\n\n  logic [31:0] sum_temp;\n  logic carry_temp;\n\n  assign {carry_temp, sum_temp} = A + B + cin;\n  assign sum = sum_temp;\n  assign cout = carry_temp;\nendmodule\n\nmodule top (\n  input logic [31:0] A,\n  input logic [31:0] B,\n  input logic cin,\n  output logic [31:0] sum,\n  output logic cout\n);\n\nadder adder_inst (\n  .A(A),\n  .B(B),\n  .cin(cin),\n  .sum(sum),\n  .cout(cout)\n);\nendmodule\n\nendmodule\n\\end{code}\n\nThe `adder` module is a\n---------------------------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"USER CASE 3\")\nprompt = f\"Correct the following code \\n{incorrect_code}\\n\\nCorrect code:\\n\"        \ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\nsample = model.generate(input_ids, pad_token_id=tokenizer.pad_token_id, max_length=256, temperature=0.5, top_p=0.9)\nprint(tokenizer.decode(sample[0]))\nprint(dash_line)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:09:12.699285Z","iopub.execute_input":"2024-06-09T09:09:12.700063Z","iopub.status.idle":"2024-06-09T09:09:25.311898Z","shell.execute_reply.started":"2024-06-09T09:09:12.700016Z","shell.execute_reply":"2024-06-09T09:09:25.310814Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"USER CASE 3\n<s> Correct the following code \n\n    module half_adder(a,b,s,cout);\n\n    input a,b;\n    output s,cout;\n\n    assign s  a * b;\n    assign cout = a & b;\n\n    endmodule\n\nCorrect code:\n\nmodule half_adder(a,b,s,cout);\n\ninput a,b;\noutput s,cout;\n\nassign s = a * b;\nassign cout = a & b;\n\nendmodule\n\nEnd of code\n\nCan someone please explain why the code is corrected?\n\nI understand that the error was in the input statement, but I don't understand why the output statements were also corrected.\n\nThanks in advance.\n\nAnswer:\n\nThe error in the input statement was due to the fact that the input variables `a` and `b` were not properly declared as inputs to the module. In VHDL, inputs are declared using the `input` keyword, followed by the name of the variable and its data type.\n\nFor example:\n\nmodule half_adder(a: in  bit; b: in \n---------------------------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"USER CASE 3\")\nprompt = f\"Correct the following code \\n{incorrect_code}\\n\\nCorrect code:\\n\"        \ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\nsample = model.generate(input_ids, pad_token_id=tokenizer.pad_token_id, max_length=256, temperature=0.5, top_p=0.9)\nprint(tokenizer.decode(sample[0]))\nprint(dash_line)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:09:25.313091Z","iopub.execute_input":"2024-06-09T09:09:25.314885Z","iopub.status.idle":"2024-06-09T09:09:37.817459Z","shell.execute_reply.started":"2024-06-09T09:09:25.314855Z","shell.execute_reply":"2024-06-09T09:09:37.816498Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"USER CASE 3\n<s> Correct the following code \n\n    module half_adder(a,b,s,cout);\n\n    input a,b;\n    output s,cout;\n\n    assign s  a * b;\n    assign cout = a & b;\n\n    endmodule\n\nCorrect code:\n\nmodule half_adder(a,b,s,cout);\n\ninput a,b;\noutput s,cout;\n\nassign s = a * b;\nassign cout = a & b;\n\nendmodule\n\nEnd of code\n\nCan someone please explain why the code is corrected?\n\nI understand that the error was in the input statement, but I don't understand why the output statements were also corrected.\n\nThanks in advance.\n\nAnswer:\n\nThe error in the input statement was due to the fact that the input variables `a` and `b` were not properly declared as inputs to the module. In VHDL, inputs are declared using the `input` keyword, followed by the name of the variable and its data type.\n\nFor example:\n\nmodule half_adder(a: in  bit; b: in \n---------------------------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Finetuning the model","metadata":{}},{"cell_type":"code","source":"def create_prompt_formats(df):\n    \"\"\"\n    Format various fields of the sample ('instruction','output')\n    Then concatenate them using two newline characters \n    :param sample: Sample dictionnary\n    \"\"\"\n    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n    INSTRUCTION_KEY = \"### Instruct: Correct the following Verilog code\"\n    RESPONSE_KEY = \"### Output:\"\n    END_KEY = \"### End\"\n    \n    blurb = f\"\\n{INTRO_BLURB}\"\n    instruction = f\"{INSTRUCTION_KEY}\"\n    input_context = f\"{df['Error']}\"\n    response = f\"{RESPONSE_KEY}\\n{df['Correct']}\"\n    end = f\"{END_KEY}\"\n    \n    parts = [part for part in [blurb, instruction, input_context, response, end] if part]\n\n    formatted_prompt = \"\\n\\n\".join(parts)\n    df[\"prompt\"] = formatted_prompt\n\n    return df\n\n\ndef get_max_length(model):\n    conf = model.config\n    max_length = None\n    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n        max_length = getattr(model.config, length_setting, None)\n        if max_length:\n            print(f\"Found max lenth: {max_length}\")\n            break\n    if not max_length:\n        max_length = 1024\n        print(f\"Using default max length: {max_length}\")\n    return max_length\n\n\n\ndef preprocess_batch(batch, tokenizer, max_length):\n    \"\"\"\n    Tokenizing a batch\n    \"\"\"\n    return tokenizer(\n        batch[\"text\"],\n        max_length=max_length,\n        truncation=True,\n    )\n\n\ndef preprocess_dataset(tokenizer: AutoTokenizer, max_length: int,seed, dataset):\n    \"\"\"Format & tokenize it so it is ready for training\n    :param tokenizer (AutoTokenizer): Model Tokenizer\n    :param max_length (int): Maximum number of tokens to emit from tokenizer\n    \"\"\"\n    \n    print(\"Preprocessing dataset...\")\n    dataset = create_prompt_formats(dataset)\n    return dataset\n    \n#     _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n#     dataset = dataset.map(\n#         _preprocessing_function,\n#         batched=True,\n#     )\n\n#     # Filter out samples that have input_ids exceeding max_length\n#     dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n    \n#     # Shuffle dataset\n#     dataset = dataset.shuffle(seed=seed)\n\n#     return dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:11:38.883934Z","iopub.execute_input":"2024-06-09T09:11:38.884380Z","iopub.status.idle":"2024-06-09T09:11:38.895297Z","shell.execute_reply.started":"2024-06-09T09:11:38.884335Z","shell.execute_reply":"2024-06-09T09:11:38.894184Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:11:42.453188Z","iopub.execute_input":"2024-06-09T09:11:42.454049Z","iopub.status.idle":"2024-06-09T09:11:42.470375Z","shell.execute_reply.started":"2024-06-09T09:11:42.454011Z","shell.execute_reply":"2024-06-09T09:11:42.469468Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"                                                 Error  \\\n0    /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n1    // Two modules are built as part of solution\\n...   \n2    module half_adder(input a, b, output s0, c0);\\...   \n3    /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n4    /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n..                                                 ...   \n495  //# 62 inputs\\n //# 152 outputs\\n //# 638 D-ty...   \n496  /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n497  module ram_single #(\\n  parameter DATA_WIDTH=8...   \n498  /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n499  // This takes two signed 4 bit numbers and out...   \n\n                                               Correct  \n0    /*\\n * Copyright 2012, Homer Hsing <homer.hsin...  \n1    // Two modules are built as part of solution\\n...  \n2    module half_adder(input a, b, output s0, c0);\\...  \n3    /*\\n * Copyright 2012, Homer Hsing <homer.hsin...  \n4    /*\\n * Copyright 2012, Homer Hsing <homer.hsin...  \n..                                                 ...  \n495  //# 62 inputs\\n//# 152 outputs\\n//# 638 D-type...  \n496  /*\\n * Copyright 2012, Homer Hsing <homer.hsin...  \n497  module ram_single #(\\n  parameter DATA_WIDTH=8...  \n498  /*\\n * Copyright 2012, Homer Hsing <homer.hsin...  \n499  // This takes two signed 4 bit numbers and out...  \n\n[500 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Error</th>\n      <th>Correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>// Two modules are built as part of solution\\n...</td>\n      <td>// Two modules are built as part of solution\\n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>module half_adder(input a, b, output s0, c0);\\...</td>\n      <td>module half_adder(input a, b, output s0, c0);\\...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>//# 62 inputs\\n //# 152 outputs\\n //# 638 D-ty...</td>\n      <td>//# 62 inputs\\n//# 152 outputs\\n//# 638 D-type...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>module ram_single #(\\n  parameter DATA_WIDTH=8...</td>\n      <td>module ram_single #(\\n  parameter DATA_WIDTH=8...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>// This takes two signed 4 bit numbers and out...</td>\n      <td>// This takes two signed 4 bit numbers and out...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"max_length = get_max_length(model)\ntrain_dataset = create_prompt_formats(dataset)\ntrain_dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:11:44.884227Z","iopub.execute_input":"2024-06-09T09:11:44.884893Z","iopub.status.idle":"2024-06-09T09:11:44.910907Z","shell.execute_reply.started":"2024-06-09T09:11:44.884857Z","shell.execute_reply":"2024-06-09T09:11:44.909809Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Found max lenth: 4096\n","output_type":"stream"},{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"                                                 Error  \\\n0    /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n1    // Two modules are built as part of solution\\n...   \n2    module half_adder(input a, b, output s0, c0);\\...   \n3    /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n4    /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n..                                                 ...   \n495  //# 62 inputs\\n //# 152 outputs\\n //# 638 D-ty...   \n496  /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n497  module ram_single #(\\n  parameter DATA_WIDTH=8...   \n498  /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...   \n499  // This takes two signed 4 bit numbers and out...   \n\n                                               Correct  \\\n0    /*\\n * Copyright 2012, Homer Hsing <homer.hsin...   \n1    // Two modules are built as part of solution\\n...   \n2    module half_adder(input a, b, output s0, c0);\\...   \n3    /*\\n * Copyright 2012, Homer Hsing <homer.hsin...   \n4    /*\\n * Copyright 2012, Homer Hsing <homer.hsin...   \n..                                                 ...   \n495  //# 62 inputs\\n//# 152 outputs\\n//# 638 D-type...   \n496  /*\\n * Copyright 2012, Homer Hsing <homer.hsin...   \n497  module ram_single #(\\n  parameter DATA_WIDTH=8...   \n498  /*\\n * Copyright 2012, Homer Hsing <homer.hsin...   \n499  // This takes two signed 4 bit numbers and out...   \n\n                                                prompt  \n0    \\nBelow is an instruction that describes a tas...  \n1    \\nBelow is an instruction that describes a tas...  \n2    \\nBelow is an instruction that describes a tas...  \n3    \\nBelow is an instruction that describes a tas...  \n4    \\nBelow is an instruction that describes a tas...  \n..                                                 ...  \n495  \\nBelow is an instruction that describes a tas...  \n496  \\nBelow is an instruction that describes a tas...  \n497  \\nBelow is an instruction that describes a tas...  \n498  \\nBelow is an instruction that describes a tas...  \n499  \\nBelow is an instruction that describes a tas...  \n\n[500 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Error</th>\n      <th>Correct</th>\n      <th>prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n      <td>\\nBelow is an instruction that describes a tas...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>// Two modules are built as part of solution\\n...</td>\n      <td>// Two modules are built as part of solution\\n...</td>\n      <td>\\nBelow is an instruction that describes a tas...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>module half_adder(input a, b, output s0, c0);\\...</td>\n      <td>module half_adder(input a, b, output s0, c0);\\...</td>\n      <td>\\nBelow is an instruction that describes a tas...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n      <td>\\nBelow is an instruction that describes a tas...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n      <td>\\nBelow is an instruction that describes a tas...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>//# 62 inputs\\n //# 152 outputs\\n //# 638 D-ty...</td>\n      <td>//# 62 inputs\\n//# 152 outputs\\n//# 638 D-type...</td>\n      <td>\\nBelow is an instruction that describes a tas...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n      <td>\\nBelow is an instruction that describes a tas...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>module ram_single #(\\n  parameter DATA_WIDTH=8...</td>\n      <td>module ram_single #(\\n  parameter DATA_WIDTH=8...</td>\n      <td>\\nBelow is an instruction that describes a tas...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>/*\\n  * Copyright 2012, Homer Hsing &lt;homer.hsi...</td>\n      <td>/*\\n * Copyright 2012, Homer Hsing &lt;homer.hsin...</td>\n      <td>\\nBelow is an instruction that describes a tas...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>// This takes two signed 4 bit numbers and out...</td>\n      <td>// This takes two signed 4 bit numbers and out...</td>\n      <td>\\nBelow is an instruction that describes a tas...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T09:12:27.900251Z","iopub.execute_input":"2024-06-09T09:12:27.901302Z","iopub.status.idle":"2024-06-09T09:12:27.906768Z","shell.execute_reply.started":"2024-06-09T09:12:27.901255Z","shell.execute_reply":"2024-06-09T09:12:27.905611Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruct: Correct the following Verilog code\n\n0      /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...\n1      // Two modules are built as part of solution\\n...\n2      module half_adder(input a, b, output s0, c0);\\...\n3      /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...\n4      /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...\n                             ...                        \n495    //# 62 inputs\\n //# 152 outputs\\n //# 638 D-ty...\n496    /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...\n497    module ram_single #(\\n  parameter DATA_WIDTH=8...\n498    /*\\n  * Copyright 2012, Homer Hsing <homer.hsi...\n499    // This takes two signed 4 bit numbers and out...\nName: Error, Length: 500, dtype: object\n\n### Output:\n0      /*\\n * Copyright 2012, Homer Hsing <homer.hsin...\n1      // Two modules are built as part of solution\\n...\n2      module half_adder(input a, b, output s0, c0);\\...\n3      /*\\n * Copyright 2012, Homer Hsing <homer.hsin...\n4      /*\\n * Copyright 2012, Homer Hsing <homer.hsin...\n                             ...                        \n495    //# 62 inputs\\n//# 152 outputs\\n//# 638 D-type...\n496    /*\\n * Copyright 2012, Homer Hsing <homer.hsin...\n497    module ram_single #(\\n  parameter DATA_WIDTH=8...\n498    /*\\n * Copyright 2012, Homer Hsing <homer.hsin...\n499    // This takes two signed 4 bit numbers and out...\nName: Correct, Length: 500, dtype: object\n\n### End\n","output_type":"stream"}]}]}